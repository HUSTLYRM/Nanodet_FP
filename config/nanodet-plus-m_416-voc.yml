save_dir: /home/zengyj/nanodet/nanodet-main/workspace/nanodetfp_416 # 存放训练结果的路径(包括了训练的日志以及保存的模型)

model:
  weight_averager:                 # 不太清楚, 默认就好了
    name: ExpMovingAverager
    decay: 0.9998
  arch:
    name: NanoDetPlus              # NanoDetPlus
    detach_epoch: 10               # detach()
    backbone:
      name: ShuffleNetV2           # 默认使用shuffleNetV2
      model_size: 1.0x             # 模型缩放系数，更大的模型就是相应地扩大各层feature map的大小
      out_stages: [2,3,4]          # backbone中输出特征到FPN的stage
      activation: LeakyReLU        # 激活函数
    fpn:
      name: GhostPAN               # 用ghostNet的模块对不同特征层进行融合
      in_channels: [116, 232, 464] # 输入fpn的geature map 尺寸, 要和backbone即shufflenetv2的输出的stage的通道数匹配
      out_channels: 96             # neck输出的通道数
      kernel_size: 5               # 卷积核大小
      num_extra_level: 1           # 增加 额外的卷积层（看代码）
      use_depthwise: True          # 使用深度可分离卷积
      activation: LeakyReLU        # 激活函数
    head:                        
      name: NanoDetPlusHead        # 检测头
      num_classes: 36              # 类别数
      input_channel: 96            # 输入通道数
      feat_channels: 96            # 特征通道数
      stacked_convs: 2             # head的卷积层数
      kernel_size: 5               # 卷积核的大小
      strides: [8, 16, 32, 64]     # 四个头，分别对应了不同尺度特征的检测，不同head检测时的下采样倍数
      activation: LeakyReLU        # 激活函数
      reg_max: 7                   # 用于dfl的参数，head的回归分支会预测框的分布，即用回归reg_max+1个离散的几个值来表示一个分布
      norm_cfg:
        type: BN                   # head选用batch norm 进行归一化操作
      loss:                        # TODO 摸索一下loss_weight，去找到一个还比较合适的 
        loss_qfl:
          name: QualityFocalLoss   # loss继承了nanodet，使用GFL，并且这些loss有不同的权重
          use_sigmoid: True
          beta: 2.0
          loss_weight: 1.0
        loss_dfl:
          name: DistributionFocalLoss
          loss_weight: 0.25
        loss_bbox:                  # 增加一下bbox的损失函数的权重, 
          name: GIoULoss
          loss_weight: 2.0
          # loss_weight: 20.0
        # loss_pts:                  
        #   name: WingLoss            # TODO 这里新增了loss_pts   (没增加这里的时候，也能正常训练)  这里是看了300个epoch训练后的数据，发现300个epoch的效果不明显
        #   loss_weight: 0.05
        # loss_poly_iou:
        #   name: PolyIOUloss
        #   loss_weight: 1.0
    
    # Auxiliary head, only use in training time.
    # 新增的辅助模块，（常规检测头，表达能力更强，只在训练的时候用）
    aux_head:
      name: SimpleConvHead
      num_classes: 36             # 类别
      input_channel: 192          # 输入通道数
      feat_channels: 192
      stacked_convs: 4            # 四层卷积
      strides: [8, 16, 32, 64]    # 对应四个头
      activation: LeakyReLU
      reg_max: 7


# 测试用的数据集的需求

# swu_dataset 数据集中 比较多的 几个
#   B1:  583 张
#   B2： 594 张
#   B3： 1100 张
#   B4:  836 张
#   B5： 657 张
#   BO:  438 张
#   BBb: 618张
#   R1： 493 张
#   R2:  485 张
#   R3： 642 张
#   R4： 1235 张
#   R5： 860 张

# VOC格式数据
class_names: &class_names ['B_G', 'B_1', 'B_2', 'B_3', 'B_4', 'B_5', 'B_O', 'B_Bs', 'B_Bb',   # 0-8
                           'R_G', 'R_1', 'R_2', 'R_3', 'R_4', 'R_5', 'R_O', 'R_Bs', 'R_Bb',   # 9-17
                           'N_G', 'N_1', 'N_2', 'N_3', 'N_4', 'N_5', 'N_O', 'N_Bs', 'N_Bb',   # 18-26
                           'P_G', 'P_1', 'P_2', 'P_3', 'P_4', 'P_5', 'P_O', 'P_Bs', 'P_Bb' ]  # 27-35       #Please fill in the category names (not include background category)

data:                                                               # 数据集设置相关
  train:
    name: XMLDataset                                                # 采用XML格式的数据集
    class_names: *class_names
    img_path: /home/zengyj/nanodet/swu_dataset/train/image          # Please fill in train image path
    ann_path: /home/zengyj/nanodet/swu_dataset/train/xml            # Please fill in train xml path
    input_size: [416,416]                                           # [w,h], 根据输入网络的尺寸进行更改
    keep_ratio: False                                               # TODO 注意：使用了keep_ratio时，网络单个feat尺寸也会发生一定的变化（例如40x40变成了32x40（原尺寸1024x1280））
    pipeline:
      perspective: 0.0
      scale: [0.6, 1.4]                                            # TODO 把这些增强操作pipeline关闭，`暂时`不考虑 ( 开启后 wrap映射 比较复杂 )
      stretch: [[1, 1], [1, 1]]
      rotation: 0
      shear: 0
      translate: 0.2
      flip: 0.5
      brightness: 0.2                                               # 不是尺寸变化的可以先保留
      contrast: [0.8, 1.2]
      saturation: [0.8, 1.2]
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]
  val:
    name: XMLDataset
    class_names: *class_names                                       # 这里随后要修改
    img_path: /home/zengyj/nanodet/swu_dataset/test/image           # Please fill in val image path
    ann_path: /home/zengyj/nanodet/swu_dataset/test/xml             # Please fill in val xml path
    input_size: [416,416]                                           # [w,h]
    keep_ratio: False
    pipeline:
      normalize: [[103.53, 116.28, 123.675], [57.375, 57.12, 58.395]]

device:
  gpu_ids: [0]                                                      # Set like [0, 1, 2, 3] if you have multi-GPUs
  workers_per_gpu: 16                                               # TODO  命令行中给出的提示，支持16个进程处理，建议num_workers修改成16, 根据提示修改的
  batchsize_per_gpu: 32                                             # TODO  根据显存做出合理的调整，充分发挥gpu的性能

schedule:                                                           # 训练策略相关
  # resume:                                                         # 恢复训练时设置，进行新的训练时，注意不需要设置
  #   load_model: /home/zengyj/nanodet/nanodet-main/workspace/nanodet-plus-m_416/model_last.ckpt
  optimizer:
    name: AdamW                                                     # 选择优化器
    lr: 0.001
    weight_decay: 0.05
  warmup:                                                           # warmup策略，模型训练之初选用较小的学习率，训练一段时间后使用预设的学习率进行训练
    name: linear
    steps: 500                                                      # steps 更新多少次梯度，每一个batchsize训练后进行一次更新
    ratio: 0.0001
  total_epochs: 600                                                 # 总的训练epoch
  lr_schedule:
    name: CosineAnnealingLR
    T_max: 300
    eta_min: 0.00005
  val_intervals: 10                                                 # 每个几轮训练，进行一次验证
grad_clip: 35
evaluator:
  name: CocoDetectionEvaluator
  save_key: mAP

log:
  interval: 10